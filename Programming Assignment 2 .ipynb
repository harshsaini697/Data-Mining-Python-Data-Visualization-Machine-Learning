{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 4334/5334 Programming Assignment P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall 2018\n",
    "\n",
    "## Due: 11:59pm Central Time, Wednesday, November 21, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the materials in this instruction notebook are adapted from \"Introduction to Machine Learning with Python\" by Andreas C. Mueller and Sarah Guido.\n",
    "\n",
    "To run the examples in this notebook and to finish your assignment, you need a few Python modules. If you already have a Python installation set up, you can use pip to install all of these packages:\n",
    "\n",
    "$ pip install numpy matplotlib ipython jupyter scikit-learn pandas graphviz\n",
    "\n",
    "In your python code, you will always need to import a subset of the following modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. The Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset that we use in this notebook is included in scikit-learn, a popular machine learning library for Python. The dataset is the Wisconsin Breast Cancer dataset, which records clinical measurements of breast cancer tumors. Each tumor is labeled as “benign” (for harmless tumors) or “malignant” (for cancerous tumors), and the task is to learn to predict whether a tumor is malignant based on the measurements of the tissue.\n",
    "\n",
    "The data can be loaded using the load_breast_cancer function from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "cancer.keys(): dict_keys(['data', 'DESCR', 'target', 'filename', 'feature_names', 'target_names'])\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(cancer.target)\n",
    "print(\"cancer.keys(): {}\".format(cancer.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets that are included in scikit-learn are usually stored as Bunch objects, which contain some information about the dataset as well as the actual data. All you need to know about Bunch objects is that they behave like dictionaries, with the added benefit that you can access values using a dot (as in bunch.key instead of bunch['key'])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 569 data points, with 30 features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cancer data: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of cancer data: {}\".format(cancer.data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these 569 data points, 212 are labeled as malignant and 357 as benign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts per class:\n",
      "{'benign': 357, 'malignant': 212}\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample counts per class:\\n{}\".format(\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a description of the semantic meaning of each feature, we can have a look at the feature_names attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature names:\\n{}\".format(cancer.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the names of the features (attributes) and the values in the target (class attribute), and the first 3 instances in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension'] ['malignant' 'benign']\n",
      "[  1.79900000e+01   1.03800000e+01   1.22800000e+02   1.00100000e+03\n",
      "   1.18400000e-01   2.77600000e-01   3.00100000e-01   1.47100000e-01\n",
      "   2.41900000e-01   7.87100000e-02   1.09500000e+00   9.05300000e-01\n",
      "   8.58900000e+00   1.53400000e+02   6.39900000e-03   4.90400000e-02\n",
      "   5.37300000e-02   1.58700000e-02   3.00300000e-02   6.19300000e-03\n",
      "   2.53800000e+01   1.73300000e+01   1.84600000e+02   2.01900000e+03\n",
      "   1.62200000e-01   6.65600000e-01   7.11900000e-01   2.65400000e-01\n",
      "   4.60100000e-01   1.18900000e-01] 0\n",
      "[  2.05700000e+01   1.77700000e+01   1.32900000e+02   1.32600000e+03\n",
      "   8.47400000e-02   7.86400000e-02   8.69000000e-02   7.01700000e-02\n",
      "   1.81200000e-01   5.66700000e-02   5.43500000e-01   7.33900000e-01\n",
      "   3.39800000e+00   7.40800000e+01   5.22500000e-03   1.30800000e-02\n",
      "   1.86000000e-02   1.34000000e-02   1.38900000e-02   3.53200000e-03\n",
      "   2.49900000e+01   2.34100000e+01   1.58800000e+02   1.95600000e+03\n",
      "   1.23800000e-01   1.86600000e-01   2.41600000e-01   1.86000000e-01\n",
      "   2.75000000e-01   8.90200000e-02] 0\n",
      "[  1.96900000e+01   2.12500000e+01   1.30000000e+02   1.20300000e+03\n",
      "   1.09600000e-01   1.59900000e-01   1.97400000e-01   1.27900000e-01\n",
      "   2.06900000e-01   5.99900000e-02   7.45600000e-01   7.86900000e-01\n",
      "   4.58500000e+00   9.40300000e+01   6.15000000e-03   4.00600000e-02\n",
      "   3.83200000e-02   2.05800000e-02   2.25000000e-02   4.57100000e-03\n",
      "   2.35700000e+01   2.55300000e+01   1.52500000e+02   1.70900000e+03\n",
      "   1.44400000e-01   4.24500000e-01   4.50400000e-01   2.43000000e-01\n",
      "   3.61300000e-01   8.75800000e-02] 0\n",
      "[  1.14200000e+01   2.03800000e+01   7.75800000e+01   3.86100000e+02\n",
      "   1.42500000e-01   2.83900000e-01   2.41400000e-01   1.05200000e-01\n",
      "   2.59700000e-01   9.74400000e-02   4.95600000e-01   1.15600000e+00\n",
      "   3.44500000e+00   2.72300000e+01   9.11000000e-03   7.45800000e-02\n",
      "   5.66100000e-02   1.86700000e-02   5.96300000e-02   9.20800000e-03\n",
      "   1.49100000e+01   2.65000000e+01   9.88700000e+01   5.67700000e+02\n",
      "   2.09800000e-01   8.66300000e-01   6.86900000e-01   2.57500000e-01\n",
      "   6.63800000e-01   1.73000000e-01] 0\n",
      "[  2.02900000e+01   1.43400000e+01   1.35100000e+02   1.29700000e+03\n",
      "   1.00300000e-01   1.32800000e-01   1.98000000e-01   1.04300000e-01\n",
      "   1.80900000e-01   5.88300000e-02   7.57200000e-01   7.81300000e-01\n",
      "   5.43800000e+00   9.44400000e+01   1.14900000e-02   2.46100000e-02\n",
      "   5.68800000e-02   1.88500000e-02   1.75600000e-02   5.11500000e-03\n",
      "   2.25400000e+01   1.66700000e+01   1.52200000e+02   1.57500000e+03\n",
      "   1.37400000e-01   2.05000000e-01   4.00000000e-01   1.62500000e-01\n",
      "   2.36400000e-01   7.67800000e-02] 0\n",
      "[  1.24500000e+01   1.57000000e+01   8.25700000e+01   4.77100000e+02\n",
      "   1.27800000e-01   1.70000000e-01   1.57800000e-01   8.08900000e-02\n",
      "   2.08700000e-01   7.61300000e-02   3.34500000e-01   8.90200000e-01\n",
      "   2.21700000e+00   2.71900000e+01   7.51000000e-03   3.34500000e-02\n",
      "   3.67200000e-02   1.13700000e-02   2.16500000e-02   5.08200000e-03\n",
      "   1.54700000e+01   2.37500000e+01   1.03400000e+02   7.41600000e+02\n",
      "   1.79100000e-01   5.24900000e-01   5.35500000e-01   1.74100000e-01\n",
      "   3.98500000e-01   1.24400000e-01] 0\n",
      "[  1.82500000e+01   1.99800000e+01   1.19600000e+02   1.04000000e+03\n",
      "   9.46300000e-02   1.09000000e-01   1.12700000e-01   7.40000000e-02\n",
      "   1.79400000e-01   5.74200000e-02   4.46700000e-01   7.73200000e-01\n",
      "   3.18000000e+00   5.39100000e+01   4.31400000e-03   1.38200000e-02\n",
      "   2.25400000e-02   1.03900000e-02   1.36900000e-02   2.17900000e-03\n",
      "   2.28800000e+01   2.76600000e+01   1.53200000e+02   1.60600000e+03\n",
      "   1.44200000e-01   2.57600000e-01   3.78400000e-01   1.93200000e-01\n",
      "   3.06300000e-01   8.36800000e-02] 0\n",
      "[  1.37100000e+01   2.08300000e+01   9.02000000e+01   5.77900000e+02\n",
      "   1.18900000e-01   1.64500000e-01   9.36600000e-02   5.98500000e-02\n",
      "   2.19600000e-01   7.45100000e-02   5.83500000e-01   1.37700000e+00\n",
      "   3.85600000e+00   5.09600000e+01   8.80500000e-03   3.02900000e-02\n",
      "   2.48800000e-02   1.44800000e-02   1.48600000e-02   5.41200000e-03\n",
      "   1.70600000e+01   2.81400000e+01   1.10600000e+02   8.97000000e+02\n",
      "   1.65400000e-01   3.68200000e-01   2.67800000e-01   1.55600000e-01\n",
      "   3.19600000e-01   1.15100000e-01] 0\n",
      "[  1.30000000e+01   2.18200000e+01   8.75000000e+01   5.19800000e+02\n",
      "   1.27300000e-01   1.93200000e-01   1.85900000e-01   9.35300000e-02\n",
      "   2.35000000e-01   7.38900000e-02   3.06300000e-01   1.00200000e+00\n",
      "   2.40600000e+00   2.43200000e+01   5.73100000e-03   3.50200000e-02\n",
      "   3.55300000e-02   1.22600000e-02   2.14300000e-02   3.74900000e-03\n",
      "   1.54900000e+01   3.07300000e+01   1.06200000e+02   7.39300000e+02\n",
      "   1.70300000e-01   5.40100000e-01   5.39000000e-01   2.06000000e-01\n",
      "   4.37800000e-01   1.07200000e-01] 0\n",
      "[  1.24600000e+01   2.40400000e+01   8.39700000e+01   4.75900000e+02\n",
      "   1.18600000e-01   2.39600000e-01   2.27300000e-01   8.54300000e-02\n",
      "   2.03000000e-01   8.24300000e-02   2.97600000e-01   1.59900000e+00\n",
      "   2.03900000e+00   2.39400000e+01   7.14900000e-03   7.21700000e-02\n",
      "   7.74300000e-02   1.43200000e-02   1.78900000e-02   1.00800000e-02\n",
      "   1.50900000e+01   4.06800000e+01   9.76500000e+01   7.11400000e+02\n",
      "   1.85300000e-01   1.05800000e+00   1.10500000e+00   2.21000000e-01\n",
      "   4.36600000e-01   2.07500000e-01] 0\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names,cancer.target_names)\n",
    "for i in range(0,10):\n",
    "    print(cancer.data[i], cancer.target[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find out more about the data by reading cancer.DESCR if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. k-Nearest Neighbor\n",
    "#### k-Neighbors Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look at how we can apply the k-nearest neighbors algorithm using scikit-learn. First, we split our data into a training and a test set so we can evaluate generalization performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this function randomly partitions the dataset into training and test sets. The randomness is controlled by a pseudo random number generator, which generates random numbers using a seed. If you fix the seed, you will actually always get the same partition (thus no randomness). That is why we set random_state=0. (We can also use any other fixed number instead of 0, to acheive the same effect.) It guarantees that you reproduce the same results in every run. It is useful in testing your programs. However, in your real production code where randomness is needed, you shouldn't fix random_state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the KNeighborsClassifier class. This is when we can set parameters, like the number of neighbors to use. Here, we set it to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the classifier using the training set. For KNeighborsClassifier this means storing the dataset, so we can compute neighbors during prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_feature, train_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions on the test data, we call the predict method. For each data point in the test set, this computes its nearest neighbors in the training set and finds the most common class among these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      "[0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set predictions:\\n{}\".format(knn.predict(test_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how well our model generalizes, we can call the score method with the test data together with the test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy: {:.2f}\".format(knn.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model is about 92% accurate, meaning the model predicted the class correctly for 92% of the samples in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s investigate whether we can confirm the connection between model complexity and generalization. For that, we evaluate training and test set performance with different numbers of neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10.\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(train_feature, train_class)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(knn.score(train_feature, train_class))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(knn.score(test_feature, test_class))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the training and test set accuracy on the y-axis against the setting of n_neighbors on the x-axis. While real-world plots are rarely very smooth, we can still recognize some of the characteristics of overfitting and underfitting. Considering a single nearest neighbor, the prediction on the training set is perfect. But when more neighbors are considered, the model becomes simpler and the training accuracy drops. The test set accuracy for using a single neighbor is lower than when using more neighbors, indicating that using the single nearest neighbor leads to a model that is too complex. On the other hand, when considering 10 neighbors, the model is too simple and performance is even worse. (It is not a typo. Yes, using less neighbors leads to more complex models. Think carefully about this.) The best performance is somewhere in the middle, using around six neighbors. Still, it is good to keep the scale of the plot in mind. The worst performance is around 88% accuracy, which might still be acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear support vector machines (linear SVMs) is implemented in svm.LinearSVC. Let's apply it on the brest cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "linearsvm = LinearSVC(random_state=0).fit(train_feature, train_class)\n",
    "print(\"Test set score: {:.3f}\".format(linearsvm.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are also implemented in scikit-learn. Since the features in the breast cancer dataset are all continuous numeric attributes, let's use GaussianNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "nb = GaussianNB().fit(train_feature, train_class)\n",
    "print(\"Test set score: {:.3f}\".format(nb.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are also implmented in scikit-learn. Let's use DecisionTreeClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "uuid": "6e5d7a76-9bba-42f7-b26e-907775d289b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(train_feature, train_class)\n",
    "print(\"Training set score: {:.3f}\".format(tree.score(train_feature, train_class)))\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don’t restrict the depth of a decision tree, the tree can become arbitrarily deep and complex. Unpruned trees are therefore prone to overfitting and not generalizing well to new data. Now let’s apply pre-pruning to the tree, which will stop developing the tree before we perfectly fit to the training data. One option is to stop building the tree after a certain depth has been reached. In the above code, we didn't set max_depth (i.e., max_depth= None,  which is the default value). Nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split instances (min_samples_split is another parameter in DecisionTreeClassifier). Now let's set max_depth=4, meaning only four consecutive questions can be asked. Limiting the depth of the tree decreases overfitting. This leads to a lower accuracy on the training set, but an improvement on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988\n",
      "Test set score: 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(train_feature, train_class)\n",
    "print(\"Training set score: {:.3f}\".format(tree.score(train_feature, train_class)))\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the tree using the export_graphviz function from the tree module. This writes a file in the .dot file format, which is a text file format for storing graphs. We set an option to color the nodes to reflect the majority class in each node and pass the class and features names so the tree can be properly labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1035pt\" height=\"458pt\"\n",
       " viewBox=\"0.00 0.00 1035.15 458.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 454)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-454 1031.15,-454 1031.15,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.403922\" stroke=\"black\" points=\"637.222,-450 490.991,-450 490.991,-386 637.222,-386 637.222,-450\"/>\n",
       "<text text-anchor=\"middle\" x=\"564.106\" y=\"-434.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst radius &lt;= 16.795</text>\n",
       "<text text-anchor=\"middle\" x=\"564.106\" y=\"-420.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 426</text>\n",
       "<text text-anchor=\"middle\" x=\"564.106\" y=\"-406.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [159, 267]</text>\n",
       "<text text-anchor=\"middle\" x=\"564.106\" y=\"-392.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.901961\" stroke=\"black\" points=\"564.091,-350 368.121,-350 368.121,-286 564.091,-286 564.091,-350\"/>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst concave points &lt;= 0.1359</text>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 284</text>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [25, 259]</text>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-292.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M533.099,-385.992C523.983,-376.876 513.902,-366.796 504.388,-357.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"506.795,-354.739 497.249,-350.142 501.845,-359.688 506.795,-354.739\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.249\" y=\"-370.942\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.941176\" stroke=\"black\" points=\"736.467,-350 589.746,-350 589.746,-286 736.467,-286 736.467,-350\"/>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">texture error &lt;= 0.4732</text>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 142</text>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [134, 8]</text>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-292.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>0&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M595.431,-385.992C604.64,-376.876 614.823,-366.796 624.434,-357.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"627.002,-359.665 631.646,-350.142 622.077,-354.69 627.002,-359.665\"/>\n",
       "<text text-anchor=\"middle\" x=\"631.519\" y=\"-370.942\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.984314\" stroke=\"black\" points=\"358.312,-250 215.901,-250 215.901,-186 358.312,-186 358.312,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">radius error &lt;= 1.0475</text>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 252</text>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [4, 248]</text>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M409.47,-285.992C391.513,-276.161 371.508,-265.208 352.961,-255.055\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.441,-251.875 343.989,-250.142 351.08,-258.015 354.441,-251.875\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.474510\" stroke=\"black\" points=\"537.877,-250 394.336,-250 394.336,-186 537.877,-186 537.877,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst texture &lt;= 25.62</text>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 32</text>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [21, 11]</text>\n",
       "<text text-anchor=\"middle\" x=\"466.106\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>1&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M466.106,-285.992C466.106,-277.859 466.106,-268.959 466.106,-260.378\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"469.607,-260.142 466.106,-250.142 462.607,-260.142 469.607,-260.142\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.988235\" stroke=\"black\" points=\"211.936,-150 38.277,-150 38.277,-86 211.936,-86 211.936,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"125.106\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">smoothness error &lt;= 0.0033</text>\n",
       "<text text-anchor=\"middle\" x=\"125.106\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 251</text>\n",
       "<text text-anchor=\"middle\" x=\"125.106\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [3, 248]</text>\n",
       "<text text-anchor=\"middle\" x=\"125.106\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235.849,-185.992C219.745,-176.251 201.821,-165.408 185.165,-155.332\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.955,-152.324 176.587,-150.142 183.331,-158.313 186.955,-152.324\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"344.202,-143 230.011,-143 230.011,-93 344.202,-93 344.202,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"287.106\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M287.106,-185.992C287.106,-175.646 287.106,-164.057 287.106,-153.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.607,-153.288 287.106,-143.288 283.607,-153.288 290.607,-153.288\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" points=\"96.3196,-50 -0.106681,-50 -0.106681,-0 96.3196,-0 96.3196,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.1064\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"48.1064\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 3]</text>\n",
       "<text text-anchor=\"middle\" x=\"48.1064\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.8228,-85.9375C91.14,-76.8578 82.7332,-66.9225 75.0124,-57.798\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"77.5709,-55.4032 68.4396,-50.0301 72.2272,-59.9248 77.5709,-55.4032\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.992157\" stroke=\"black\" points=\"219.645,-50 114.568,-50 114.568,-0 219.645,-0 219.645,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 247</text>\n",
       "<text text-anchor=\"middle\" x=\"167.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 245]</text>\n",
       "<text text-anchor=\"middle\" x=\"167.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.443,-85.9375C143.422,-77.3164 147.757,-67.9239 151.79,-59.1865\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.003,-60.5764 156.016,-50.0301 148.647,-57.643 155.003,-60.5764\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.666667\" stroke=\"black\" points=\"539.846,-150 362.367,-150 362.367,-86 539.846,-86 539.846,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst smoothness &lt;= 0.1786</text>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 12</text>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [3, 9]</text>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M461.36,-185.992C460.102,-177.77 458.723,-168.763 457.396,-160.095\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"460.846,-159.498 455.873,-150.142 453.927,-160.557 460.846,-159.498\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.890196\" stroke=\"black\" points=\"726.001,-150 558.212,-150 558.212,-86 726.001,-86 726.001,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"642.106\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst symmetry &lt;= 0.2682</text>\n",
       "<text text-anchor=\"middle\" x=\"642.106\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 20</text>\n",
       "<text text-anchor=\"middle\" x=\"642.106\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [18, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"642.106\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M521.794,-185.992C539.449,-176.161 559.12,-165.208 577.355,-155.055\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"579.143,-158.065 586.177,-150.142 575.738,-151.949 579.143,-158.065\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.890196\" stroke=\"black\" points=\"376.32,-50 279.893,-50 279.893,-0 376.32,-0 376.32,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"328.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"328.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 9]</text>\n",
       "<text text-anchor=\"middle\" x=\"328.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M409.121,-85.9375C396.105,-76.3076 381.787,-65.7151 368.856,-56.1483\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"370.707,-53.164 360.587,-50.0301 366.544,-58.7914 370.707,-53.164\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"508.202,-50 394.011,-50 394.011,-0 508.202,-0 508.202,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"451.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M451.106,-85.9375C451.106,-77.6833 451.106,-68.7219 451.106,-60.3053\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"454.607,-60.03 451.106,-50.0301 447.607,-60.0301 454.607,-60.03\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.498039\" stroke=\"black\" points=\"622.32,-50 525.893,-50 525.893,-0 622.32,-0 622.32,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"574.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"574.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [1, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"574.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M618.895,-85.9375C612.179,-76.9496 604.836,-67.1231 598.074,-58.0747\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"600.853,-55.9456 592.063,-50.0301 595.245,-60.1357 600.853,-55.9456\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"754.202,-50 640.011,-50 640.011,-0 754.202,-0 754.202,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"697.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 17</text>\n",
       "<text text-anchor=\"middle\" x=\"697.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [17, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"697.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>11&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M660.88,-85.9375C666.202,-77.133 672.01,-67.5239 677.385,-58.6297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"680.406,-60.3988 682.583,-50.0301 674.415,-56.778 680.406,-60.3988\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\n",
       "<polygon fill=\"#399de5\" stroke=\"black\" points=\"711.32,-243 614.893,-243 614.893,-193 711.32,-193 711.32,-243\"/>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-227.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-213.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"663.106\" y=\"-199.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M663.106,-285.992C663.106,-275.646 663.106,-264.057 663.106,-253.465\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"666.607,-253.288 663.106,-243.288 659.607,-253.288 666.607,-253.288\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.976471\" stroke=\"black\" points=\"903.429,-250 736.784,-250 736.784,-186 903.429,-186 903.429,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst concavity &lt;= 0.1907</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 137</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [134, 3]</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>14&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M712.782,-285.992C728.245,-276.34 745.441,-265.606 761.457,-255.609\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"763.585,-258.407 770.215,-250.142 759.879,-252.469 763.585,-258.407\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\n",
       "<polygon fill=\"#399de5\" fill-opacity=\"0.333333\" stroke=\"black\" points=\"895.377,-150 744.836,-150 744.836,-86 895.377,-86 895.377,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">worst texture &lt;= 30.975</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 3]</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M820.106,-185.992C820.106,-177.859 820.106,-168.959 820.106,-160.378\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"823.607,-160.142 820.106,-150.142 816.607,-160.142 823.607,-160.142\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\"><title>20</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"1027.2,-143 913.011,-143 913.011,-93 1027.2,-93 1027.2,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"970.106\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 132</text>\n",
       "<text text-anchor=\"middle\" x=\"970.106\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [132, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"970.106\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>16&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M867.567,-185.992C885.713,-174.137 906.355,-160.651 924.339,-148.901\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"926.474,-151.687 932.931,-143.288 922.645,-145.827 926.474,-151.687\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\n",
       "<polygon fill=\"#399de5\" stroke=\"black\" points=\"868.32,-50 771.893,-50 771.893,-0 868.32,-0 868.32,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [0, 3]</text>\n",
       "<text text-anchor=\"middle\" x=\"820.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M820.106,-85.9375C820.106,-77.6833 820.106,-68.7219 820.106,-60.3053\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"823.607,-60.03 820.106,-50.0301 816.607,-60.0301 823.607,-60.03\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"1000.2,-50 886.011,-50 886.011,-0 1000.2,-0 1000.2,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"943.106\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"943.106\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = [2, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"943.106\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>17&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M862.092,-85.9375C875.108,-76.3076 889.426,-65.7151 902.357,-56.1483\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"904.669,-58.7914 910.626,-50.0301 900.506,-53.164 904.669,-58.7914\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x117291ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "with open(\"./tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance in trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at the whole tree, there are some useful properties that we can derive to summarize the workings of the tree. The most commonly used summary is feature importance, which rates how important each feature is for the decision a tree makes. It is a number between 0 and 1 for each feature, where 0 means “not used at all” and 1 means “perfectly predicts the target.” The feature importances always sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "uuid": "dc2f68ee-0df0-47ed-b500-7ec99d5a0a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.01019737  0.04839825  0.          0.\n",
      "  0.0024156   0.          0.          0.          0.          0.\n",
      "  0.72682851  0.0458159   0.          0.          0.0141577   0.          0.018188\n",
      "  0.1221132   0.01188548  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our supervised models, so far we have split our dataset into a training set and a test set using the train_test_split function, built a model on the training set by calling the fit method, and evaluated it on the test set using the score method, which for classification computes the fraction of correctly classified samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn has its own function for producing confusion matrix. But, let's use pandas which is a popular Python package for data analysis. Its crosstab function produces a better-looking confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988\n",
      "Test set score: 0.951\n",
      "Confusion matrix:\n",
      "Predicted   0   1  All\n",
      "True                  \n",
      "0          49   4   53\n",
      "1           3  87   90\n",
      "All        52  91  143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(train_feature, train_class)\n",
    "print(\"Training set score: {:.3f}\".format(tree.score(train_feature, train_class)))\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(test_feature, test_class)))\n",
    "\n",
    "prediction = tree.predict(test_feature)\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(test_class, prediction, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we split our data into training and test sets is that we are interested in measuring how well our model generalizes to new, previously unseen data. We are not interested in how well our model fit the training set, but rather in how well it can make predictions for data that was not observed during training.\n",
    " \n",
    "Cross-validation is a statistical method of evaluating generalization performance that is more stable and thorough than using a split into a training and a test set. Cross-validation is implemented in scikit-learn using the cross_val_score function from the model_selection module. The parameters of the cross_val_score function are the model we want to evaluate, the training data, and the ground-truth labels. Let’s evaluate DecisionTreeClassifier on the breast cancer dataset. We can control the number of folds used by setting the cv parameter. We also summarize the cross-validation accuracy by computing the mean accuracy of the multiple folds. \n",
    "\n",
    "scikit-learn uses stratified k-fold cross-validation for classification. In stratified cross-validation, we split the data such that the proportions between classes are the same in each fold as they are in the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.92173913  0.88695652  0.9380531   0.92920354  0.90265487]\n",
      "Average cross-validation score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "scores = cross_val_score(tree, cancer.data, cancer.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. How to Save Your Trained Model into a Pickle Object\n",
    "\n",
    "Python’s pickle module serializes objects so that they can be saved to a file and loaded in a program again later on. Below we show how to save your model as a pickle object and how to load it back in your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "train_feature, test_feature, train_class, test_class = train_test_split(\n",
    "   cancer.data, cancer.target, stratify=cancer.target, random_state=0)\n",
    "\n",
    "linearsvm = LinearSVC(random_state=0).fit(train_feature, train_class)\n",
    "#store your trained model as pickle object\n",
    "joblib.dump(linearsvm, 'SVM.pkl')\n",
    "\n",
    "#load a pickle object\n",
    "trained_model = joblib.load('SVM.pkl')\n",
    "print(\"Test set score: {:.3f}\".format(trained_model.score(test_feature, test_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Details and How to Improve the Classifiers \n",
    "\n",
    "To figure out what parameters are available in the various classification methods, you can read more about the specifications of the corresponding Python classes: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "You can even read the following tutorials about these methods. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this assigment, you will use a dataset that has claims related to U.S. congressional and electoral voting. The dataset (voting_data.csv) contains four types of claims, including claims related to 'In-progress/Eventual Results of Electoral Voting' denoted as 'E', 'Votes in Congressional Voting' denoted as 'V', 'Outcome of Congressional Voting' denoted as 'O', and claims not related to these three classes \"Others\". The dataset has only two columns: 'text' and 'label'.\n",
    "\n",
    "All the files for this assignment can be downloaded from Blackboard (\"Course Materials\" > \"Programming Assignments\" > \"Programming Assignment 2 (P2)\" > \"Attached Files\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Language\n",
    "\n",
    "You are required to use Python 3.6.x. We will test your code under the particular version of Python 3.6.x. So make sure you develop your code using the same version. You are free to use anything from the Python Standard Library that comes with Python 3.6.x (https://docs.python.org/3.6/library/).\n",
    "\n",
    "\n",
    "For classification algorithms, you are allowed to use scikit learn, a free machine learning library for Python (http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
    "\n",
    "For feature extraction and data manupilation, you are allowed to use any of the following non-standard Python packages:\n",
    "\n",
    "    Pandas (http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html)  \n",
    "    Numpy (https://docs.scipy.org/doc/numpy/user/quickstart.html)    \n",
    "    NLTK (https://www.nltk.org)\n",
    "    spaCy (https://spacy.io) \n",
    "    Gensim (https://radimrehurek.com/gensim/)\n",
    "    \n",
    "In this assignment, you are not allowed to use any other non-standard Python package other than ones mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "In this assigment, you do multi-class classification to classify a sentence into one of the four classes (\"E\", \"V\", \"O\", \"Others\"). The goal is to achieve the best performance by exploring several different classifiers and features. You can define as many functions as you want, but your code must execute in the following three modes. Please also refer to section \"Sample Output\" below for the correct format of input and output. \n",
    "\n",
    "1) Training mode: The user will issue the command line below. \n",
    "        \n",
    "            python P2.py --mode train  --input input_file\n",
    "        \n",
    "Your program will train your best model on the given input file. Use 75% of the input data for training and 25% for testing. Note that you should not set random_state to a fixed value, since this is the \"production code\". The trained model will be saved as a pickle object in the same directory with your code (refer to \"How to use the pickle module\" below). Then you need to evaluate your trained model by using the test data (i.e., 25% of the input file). Print out the classification report and the confusion matrix for the trained model. Note that there are four classes of claims. Hence the confusion matrix should be 5 x 5, since we are also reporting the results for \"All\". \n",
    "\n",
    "2) Cross_validation mode: The user will issue the command line below. \n",
    "\n",
    "            python P2.py --mode cross_val --input input_file\n",
    "\n",
    "You need to use the same mothod with the same parameters in 1). However, instead of using 75%/25% train/test split, apply 10-fold stratified cross-validation. Print out the accuracy of each fold and print out the average accuracy across all the folds. \n",
    "                \n",
    "3) Predict mode: The user will issue the command line below. \n",
    "\n",
    "            python P2.py --mode predict --input input_sentence\n",
    "\n",
    "You need to load the pretrained model that you saved as pickle object in 1) and use that to make predictions on the input sentence.            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output\n",
    "\n",
    "--> python P2.py --mode train  --input voting_data.csv\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "                     precision    recall  f1-score   support\n",
    "\n",
    "                  E       0.89      0.57      0.70        14\n",
    "                  O       0.82      0.82      0.82        11\n",
    "             Others       0.72      0.78      0.75        23\n",
    "                  V       0.89      0.97      0.93        34\n",
    "          \n",
    "        avg / total       0.83      0.83      0.82        82\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "        Predicted  E   O  Others   V  All\n",
    "        True\n",
    "        E          8   0       4   2   14\n",
    "        O          0   9       2   0   11\n",
    "        Others     1   2      18   2   23\n",
    "        V          0   0       1  33   34\n",
    "        All        9  11      25  37   82\n",
    "\n",
    "--> python P2.py --mode cross_val  --input voting_data.csv\n",
    "\n",
    "        Cross-validation scores: [0.74285714 0.62857143 0.74285714 0.81818182 0.875 0.93548387 0.87096774 0.83870968 0.80645161 0.77419355]\n",
    "\n",
    "        Average cross-validation score: 0.80\n",
    "\n",
    "--> python P2.py --mode predict --input 'And as you know, nobody can reach the White House without the Hispanic vote.'\n",
    "\n",
    "        Others\n",
    "\n",
    "--> python P2.py --mode predict --input 'Barack Obama did not vote for sanctions against Iran.'\n",
    "\n",
    "        V\n",
    "\n",
    "--> python P2.py --mode predict --input '65% of Texas voters casted a ballot for Donald Trump.'\n",
    "\n",
    "        E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to Submit\n",
    "\n",
    "You are required to submit a single .py file of your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Rubrics\n",
    "\n",
    "Your program will be evaluated on correctness, efficiency, accuracy, and code quality.\n",
    "\n",
    "Make sure to thoroughly understand the grading rubrics in file \"rubrics.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_metadata": {
   "author": "Chengkai Li",
   "title": "CSE4334 P2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
